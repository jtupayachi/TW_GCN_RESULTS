[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=-1)]: Done 146 out of 200 | elapsed:    0.8s remaining:    0.3s
[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.9s finished
[Parallel(n_jobs=128)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=128)]: Done 146 out of 200 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=128)]: Done 200 out of 200 | elapsed:    0.1s finished
[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=-1)]: Done 146 out of 200 | elapsed:    1.0s remaining:    0.4s
[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    1.2s finished
[Parallel(n_jobs=128)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=128)]: Done 146 out of 200 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=128)]: Done 200 out of 200 | elapsed:    0.1s finished
[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=-1)]: Done 146 out of 200 | elapsed:    1.4s remaining:    0.5s
[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    1.7s finished
[Parallel(n_jobs=128)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=128)]: Done 146 out of 200 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=128)]: Done 200 out of 200 | elapsed:    0.1s finished
[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=-1)]: Done 146 out of 200 | elapsed:    1.9s remaining:    0.7s
[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.2s finished
[Parallel(n_jobs=128)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=128)]: Done 146 out of 200 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=128)]: Done 200 out of 200 | elapsed:    0.1s finished
[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=-1)]: Done 146 out of 200 | elapsed:    2.1s remaining:    0.8s
[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.5s finished
[Parallel(n_jobs=128)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=128)]: Done 146 out of 200 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=128)]: Done 200 out of 200 | elapsed:    0.1s finished
[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=-1)]: Done 146 out of 200 | elapsed:    2.4s remaining:    0.9s
[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    2.9s finished
[Parallel(n_jobs=128)]: Using backend ThreadingBackend with 128 concurrent workers.
[Parallel(n_jobs=128)]: Done 146 out of 200 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=128)]: Done 200 out of 200 | elapsed:    0.1s finished
............
Warning: using -h 0 may be faster
*.....................................
Warning: using -h 0 may be faster
*.
Warning: using -h 0 may be faster
*
optimization finished, #iter = 49287
obj = -13548.793139, rho = 0.824832
nSV = 3869, nBSV = 2302
................
Warning: using -h 0 may be faster
*..............................................................................
Warning: using -h 0 may be faster
*.
Warning: using -h 0 may be faster
*
optimization finished, #iter = 95046
obj = -23265.216840, rho = 0.816155
nSV = 7713, nBSV = 4221
Running with parameters: LAG_HOURS=6, DOWNLOAD_POIS=False, NUM_CLUSTERS=10, MODEL=LSTM, SEQ_LENGTH=4, ALPHA=0.66, TRAFFIC_FEATURE=True, WEATHER_FEATURE=True, ADJACENCY=True, NUM_EPOCHS=125
[37760, 37380, 37642, 37643, 37388, 37902, 38549, 37402, 37659, 38556, 38301, 37030, 37416, 38570, 37166, 38320, 37043, 37172, 37813, 37814, 38583, 38585, 37820, 38462, 37185, 38468, 38340, 37708, 38478, 37334, 37083, 38237, 37725, 37601, 38242, 37857, 37347, 37862, 37863, 37615, 37745, 37620, 38004, 37110, 38012]
          zip                 hour  ...  delay_per_mile       TTI
114758  37708  2024-01-08 14:00:00  ...       -0.144543  1.071117
199311  37030  2024-11-25 15:00:00  ...       -0.245042  1.145850
4772    37185  2024-12-13 20:00:00  ...       -0.116627  1.023439
374892  37620  2024-02-21 12:00:00  ...       -0.268849  1.085906
115270  37708  2024-01-29 22:00:00  ...       -0.028154  1.014672
147814  37708  2024-09-09 22:00:00  ...       -0.108145  1.054321
235958  37185  2024-08-16 14:00:00  ...       -0.228922  1.045705
407349  37642  2024-10-07 21:00:00  ...        0.006098  0.945904
316253  37820  2025-01-28 05:00:00  ...       -0.024579  1.003067
360648  38549  2024-03-18 00:00:00  ...       -0.024236  1.009761

[10 rows x 12 columns]
(428760, 12)
         station_zip             datetime  ...  Humidity Bucket  Precip. Bucket
7735739        37601  2024-05-03 04:00:00  ...                5               1
7033051        38012  2024-04-23 08:00:00  ...                5               1
6339802        37814  2024-04-10 22:00:00  ...               -1              -1
2306070        37862  2024-02-06 00:00:00  ...                5               1
8912377        37902  2024-11-29 16:00:00  ...               -1              -1
8918147        38556  2024-12-04 02:00:00  ...               -1              -1
8790424        38242  2024-08-08 07:00:00  ...               -1              -1
2320615        37601  2024-02-06 20:00:00  ...                4               1
8853589        37110  2024-10-05 04:00:00  ...               -1              -1
8867750        37862  2024-10-19 05:00:00  ...               -1              -1

[10 rows x 12 columns]
(428760, 12)
       charger_id  station_zip  ... charging_time_seconds  energy_kwh
50155     1988061        37863  ...                3347.0    2.631879
84963     5397731        37601  ...                3600.0    4.478858
57923    15694171        37601  ...                 370.0    5.049369
34493     1988061        37863  ...                3600.0    4.595088
99228    15332351        37388  ...                3354.0   13.075771
35955    13606061        37043  ...                  61.0    0.000000
96191     1988061        37863  ...                3600.0    5.151833
23762    13606061        37043  ...                 305.0    3.244302
4796     13164881        37620  ...                  60.0    0.000100
49172    15694171        37601  ...                 121.0    0.000000

[10 rows x 7 columns]
(55055, 7)
Empty DataFrame
Columns: [charger_id, station_zip, start_date_time, station_latitude, station_longitude, charging_time_seconds, energy_kwh]
Index: []
<class 'pandas.core.frame.DataFrame'>
Index: 55055 entries, 0 to 106306
Data columns (total 9 columns):
 #   Column                 Non-Null Count  Dtype         
---  ------                 --------------  -----         
 0   charger_id             55055 non-null  int64         
 1   station_zip            55055 non-null  int64         
 2   start_date_time        55055 non-null  datetime64[ns]
 3   station_latitude       55055 non-null  float64       
 4   station_longitude      55055 non-null  float64       
 5   charging_time_seconds  55055 non-null  float64       
 6   energy_kwh             55055 non-null  float64       
 7   month_year             55055 non-null  period[M]     
 8   year_month             55055 non-null  period[M]     
dtypes: datetime64[ns](1), float64(4), int64(2), period[M](2)
memory usage: 4.2 MB
               Period  Count_of_negatives
7  2024-08 to 2025-01              351046
5  2024-06 to 2024-11              352555
6  2024-07 to 2024-12              353604
3  2024-04 to 2024-09              354884
4  2024-05 to 2024-10              355613
1  2024-02 to 2024-07              356034
0  2024-01 to 2024-06              357385
2  2024-03 to 2024-08              358202
Value counts for energy_kWh:
 energy_kWh
-1.000000     768542
 0.000000       1284
 17.066299         2
 9.843100          2
 15.860700         2
               ...  
 5.833772          1
 0.171563          1
 2.296312          1
 2.500192          1
 43.750599         1
Name: count, Length: 47663, dtype: int64

Rows with energy_kWh == -1: 768542
Rows with energy_kWh != -1: 48974

Rows where energy_kWh == -1:
       station_id     start_date_time  ...  has_retail_shopping  has_police
0          682921 2024-01-01 00:00:00  ...                False       False
1         1785631 2024-01-01 00:00:00  ...                False       False
2         1932851 2024-01-01 00:00:00  ...                False       False
3         1933211 2024-01-01 00:00:00  ...                False       False
4         1988061 2024-01-01 00:00:00  ...                False       False
...           ...                 ...  ...                  ...         ...
817511   16311461 2025-01-31 01:00:00  ...                False       False
817512   16311861 2025-01-31 01:00:00  ...                False       False
817513   16698191 2025-01-31 01:00:00  ...                False       False
817514   16698241 2025-01-31 01:00:00  ...                False       False
817515   16698261 2025-01-31 01:00:00  ...                False       False

[768542 rows x 19 columns]

Rows where energy_kWh != -1:
       station_id     start_date_time  ...  has_retail_shopping  has_police
22        8851921 2024-01-01 00:00:00  ...                False        True
91        1988141 2024-01-01 01:00:00  ...                False       False
108       8851921 2024-01-01 01:00:00  ...                False        True
177       1988141 2024-01-01 02:00:00  ...                False       False
194       8851921 2024-01-01 02:00:00  ...                False        True
...           ...                 ...  ...                  ...         ...
817313   14083171 2025-01-30 23:00:00  ...                False       False
817352    5397731 2025-01-31 00:00:00  ...                False       False
817357    5525971 2025-01-31 00:00:00  ...                False       False
817380   13606121 2025-01-31 00:00:00  ...                False       False
817443    5525971 2025-01-31 01:00:00  ...                False       False

[48974 rows x 19 columns]
The array contains values other than 0.
Empty DataFrame
Columns: [station_id, start_date_time, count]
Index: []
Warning: The following expected features are missing and will be ignored: ['Temperature Bucket', 'Pressure Bucket', 'Wind Speed Bucket', 'Humidity Bucket', 'Precip. Bucket', 'zip']

==================================================
Training RandomForest...

Fold 1: Training on 25044 samples, validating on 25043 samples
Fold 1 Results:
RMSE: 2.8788
MSE: 8.2875
MAE: 0.9175
SMAPE: 76.9546

Fold 2: Training on 50087 samples, validating on 25043 samples
Fold 2 Results:
RMSE: 3.2622
MSE: 10.6422
MAE: 0.9355
SMAPE: 72.4055

Fold 3: Training on 75130 samples, validating on 25043 samples
Fold 3 Results:
RMSE: 3.4235
MSE: 11.7203
MAE: 0.9388
SMAPE: 70.8128

Fold 4: Training on 100173 samples, validating on 25043 samples
Fold 4 Results:
RMSE: 3.4370
MSE: 11.8128
MAE: 0.9644
SMAPE: 73.5725

Fold 5: Training on 125216 samples, validating on 25043 samples
Fold 5 Results:
RMSE: 3.6239
MSE: 13.1324
MAE: 0.9864
SMAPE: 71.7283

Evaluating RandomForest on the final test set...

Final Test Results for RandomForest:
Test RMSE: 3.5811
Test MSE: 12.8245
Test MAE: 0.9814
Test SMAPE: 74.0967

==================================================
Training SVM...

Fold 1: Training on 25044 samples, validating on 25043 samples
[LibSVM]Fold 1 Results:
RMSE: 2.8320
MSE: 8.0201
MAE: 0.4862
SMAPE: 19.7451

Fold 2: Training on 50087 samples, validating on 25043 samples
[LibSVM]Fold 2 Results:
RMSE: 3.2656
....................
Warning: using -h 0 may be faster
*.........................................................................................................
Warning: using -h 0 may be faster
*...
Warning: using -h 0 may be faster
*
optimization finished, #iter = 127979
obj = -34230.634814, rho = 0.808069
nSV = 11415, nBSV = 6115
........................
Warning: using -h 0 may be faster
*.................................................................................................................................
Warning: using -h 0 may be faster
*.......
Warning: using -h 0 may be faster
*
optimization finished, #iter = 159317
obj = -46412.038555, rho = 0.812366
nSV = 15576, nBSV = 8356
...............................
Warning: using -h 0 may be faster
*...................................................................................................................................................
Warning: using -h 0 may be faster
*..
Warning: using -h 0 may be faster
*
optimization finished, #iter = 180271
obj = -59123.632053, rho = 0.813168
nSV = 19363, nBSV = 10754
................................
Warning: using -h 0 may be faster
*...................................................................................................................................................
Warning: using -h 0 may be faster
*............
Warning: using -h 0 may be faster
*
optimization finished, #iter = 190720
obj = -73666.417808, rho = 0.797041
nSV = 23319, nBSV = 13371
MSE: 10.6642
MAE: 0.5385
SMAPE: 19.6420

Fold 3: Training on 75130 samples, validating on 25043 samples
[LibSVM]Fold 3 Results:
RMSE: 3.4104
MSE: 11.6306
MAE: 0.5856
SMAPE: 20.9445

Fold 4: Training on 100173 samples, validating on 25043 samples
[LibSVM]Fold 4 Results:
RMSE: 3.4830
MSE: 12.1310
MAE: 0.6029
SMAPE: 20.8905

Fold 5: Training on 125216 samples, validating on 25043 samples
[LibSVM]Fold 5 Results:
RMSE: 3.7268
MSE: 13.8893
MAE: 0.6799
SMAPE: 21.8644

Evaluating SVM on the final test set...
[LibSVM]
Final Test Results for SVM:
Test RMSE: 3.6922
Test MSE: 13.6320
Test MAE: 0.6547
Test SMAPE: 22.8072

==================================================
Training LinearRegression...

Fold 1: Training on 25044 samples, validating on 25043 samples
Fold 1 Results:
RMSE: 2.8239
MSE: 7.9744
MAE: 0.8742
SMAPE: 86.1117

Fold 2: Training on 50087 samples, validating on 25043 samples
Fold 2 Results:
RMSE: 3.2358
MSE: 10.4705
MAE: 0.8699
SMAPE: 75.9210

Fold 3: Training on 75130 samples, validating on 25043 samples
Fold 3 Results:
RMSE: 3.3701
MSE: 11.3577
MAE: 0.9053
SMAPE: 75.3119

Fold 4: Training on 100173 samples, validating on 25043 samples
Fold 4 Results:
RMSE: 3.4395
MSE: 11.8300
MAE: 0.9933
SMAPE: 88.0654

Fold 5: Training on 125216 samples, validating on 25043 samples
Fold 5 Results:
RMSE: 3.6732
MSE: 13.4925
MAE: 1.0475
SMAPE: 84.7110

Evaluating LinearRegression on the final test set...

Final Test Results for LinearRegression:
Test RMSE: 3.6382
Test MSE: 13.2363
Test MAE: 1.0480
Test SMAPE: 90.9838

==================================================
Training Lasso...

Fold 1: Training on 25044 samples, validating on 25043 samples
Fold 1 Results:
RMSE: 2.8139
MSE: 7.9181
MAE: 0.8788
SMAPE: 87.1612

Fold 2: Training on 50087 samples, validating on 25043 samples
Fold 2 Results:
RMSE: 3.2387
MSE: 10.4892
MAE: 0.8688
SMAPE: 72.4699

Fold 3: Training on 75130 samples, validating on 25043 samples
Fold 3 Results:
RMSE: 3.3761
MSE: 11.3981
MAE: 0.9092
SMAPE: 72.6176

Fold 4: Training on 100173 samples, validating on 25043 samples
Fold 4 Results:
RMSE: 3.4464
MSE: 11.8773
MAE: 0.9328
SMAPE: 74.2889

Fold 5: Training on 125216 samples, validating on 25043 samples
Fold 5 Results:
RMSE: 3.6833
MSE: 13.5665
MAE: 1.0091
SMAPE: 75.4437

Evaluating Lasso on the final test set...

Final Test Results for Lasso:
Test RMSE: 3.6494
Test MSE: 13.3184
Test MAE: 1.0055
Test SMAPE: 81.5649

==================================================
Training Ridge...

Fold 1: Training on 25044 samples, validating on 25043 samples
Fold 1 Results:
RMSE: 2.8238
MSE: 7.9738
MAE: 0.8740
SMAPE: 86.0857

Fold 2: Training on 50087 samples, validating on 25043 samples
Fold 2 Results:
RMSE: 3.2358
MSE: 10.4705
MAE: 0.8702
SMAPE: 75.9695

Fold 3: Training on 75130 samples, validating on 25043 samples
Fold 3 Results:
RMSE: 3.3701
MSE: 11.3577
MAE: 0.9060
SMAPE: 75.4529

Fold 4: Training on 100173 samples, validating on 25043 samples
Fold 4 Results:
RMSE: 3.4395
MSE: 11.8300
MAE: 0.9921
SMAPE: 87.8421

Fold 5: Training on 125216 samples, validating on 25043 samples
Fold 5 Results:
RMSE: 3.6732
MSE: 13.4922
MAE: 1.0503
SMAPE: 85.2328

Evaluating Ridge on the final test set...

Final Test Results for Ridge:
Test RMSE: 3.6382
Test MSE: 13.2363
Test MAE: 1.0480
Test SMAPE: 90.9824


Final Model Comparison:

RandomForest:
RMSE: 3.3251
MSE: 11.1190
MAE: 0.9485
SMAPE: 73.0947
Test RMSE: 3.5811
Test MSE: 12.8245
Test MAE: 0.9814
Test SMAPE: 74.0967

SVM:
RMSE: 3.3435
MSE: 11.2670
MAE: 0.5786
SMAPE: 20.6173
Test RMSE: 3.6922
Test MSE: 13.6320
Test MAE: 0.6547
Test SMAPE: 22.8072

LinearRegression:
RMSE: 3.3085
MSE: 11.0251
MAE: 0.9381
SMAPE: 82.0242
Test RMSE: 3.6382
Test MSE: 13.2363
Test MAE: 1.0480
Test SMAPE: 90.9838

Lasso:
RMSE: 3.3117
MSE: 11.0498
MAE: 0.9198
SMAPE: 76.3963
Test RMSE: 3.6494
Test MSE: 13.3184
Test MAE: 1.0055
Test SMAPE: 81.5649

Ridge:
RMSE: 3.3085
MSE: 11.0248
MAE: 0.9385
SMAPE: 82.1166
Test RMSE: 3.6382
Test MSE: 13.2363
Test MAE: 1.0480
Test SMAPE: 90.9824
